# Akida-Research-Project

We propose an end-to-end pipeline for energy-efficient and privacy-preserving Skin cancer classification using quantization-aware CNNs deployed as SNNs on BrainChip Akida hardware. The model is designed to support real-time inference and on-chip incremental learning in clinical edge environments.

---

## ðŸ“– Table of Contents

1. [Introduction](#introduction)
2. [Methodology](#methodology)
3. [Experiments](#experiments)
    - [Dataset Description](#datasets)
    - [Results on HAM10000](#results-on-ham10000)
    - [Comparison with SNN Baselines](#snn-comparison)
    - [Inference Latency & Energy](#latency-energy)
    - [Ablation Study](#ablation-study)
    - [Generalization on Clinical Dataset](#clinical-generalization)
4. [Installation](#installation)
5. [Citation](#citation)

---

## Introduction

Skin cancer classification is a critical step in dermatological diagnosis. Traditional CNNs struggle with:

- Deployment on low-power edge hardware
- Small and imbalanced datasets
- Privacy concerns from cloud-based inference

To overcome these, we design a quantization-aware CNN using Ghost, ECA, and SE modules that seamlessly converts into an SNN optimized for BrainChip Akida neuromorphic chips.

---

## Methodology

The architecture comprises:

- **Ghost Blocks** for low-cost feature extraction  
- **ECA and SE** for efficient attention and recalibration  
- **Quantized activations** to support CNN-to-SNN conversion  
- **Spike-compatible output head** enabling event-driven deployment  
- **SMOTE + Augmentation** for dataset balancing  
- **Akida MetaTF SDK** for conversion and on-chip learning

The model is trained on traditional GPUs and then ported to SNN via Akida tools.

---

## Experiments

### Datasets

The HAM10000 dataset is a collection of dermascopic images of common pigmented skin lesions used for training of neural networks for automated diagnosis. It comprises of 10,015 dermatoscopic images sourced from various populations and captured through diverse modalities. It encompasses a comprehensive spectrum of diagnostic categories critical to the study of pigmented lesions. These categories include Actinic keratoses and intraepithelial carcinoma/Bowen's disease (akiec), basal cell carcinoma (bcc), benign keratosis-like lesions (comprising solar lentigines, seborrheic keratoses, and lichen-planus like keratoses, bkl), dermatofibroma (df), melanoma (mel), melanocytic nevi (nv), and vascular lesions (such as angiomas, angiokeratomas, pyogenic granulomas, and hemorrhage, vasc). This dataset is tailored to aid in the training and development of machine learning models in the field of dermatology.
---

### CNN&SNN model Results on HAM10000  
(**Section IV.C**: Per-class metrics)

| Class                   | Precision | Recall | F1   | Accuracy |
|------------------------|-----------|--------|------|----------|
| Actinic keratoses      | 0.890     | 0.933  | 0.911| 0.933    |
| Basal cell carcinoma   | 0.890     | 0.901  | 0.896| 0.901    |
| Benign keratosis-like  | 0.866     | 0.853  | 0.859| 0.853    |
| Dermatofibroma         | 0.925     | 0.976  | 0.950| 0.976    |
| Melanocytic nevi       | 0.887     | 0.817  | 0.851| 0.817    |
| Vascular lesions       | 0.949     | 0.966  | 0.957| 0.966    |
| Melanoma               | 0.956     | 0.933  | 0.944| 0.933    |
| **Average**            | **0.909** | **0.911** | **0.910** | **0.910** |

> **Explanation:** This table reports the per-class classification performance. The model shows high consistency across frequent and rare lesion categories, demonstrating robustness under data imbalance.

---

### Comparison with Other Converted SNNs  
(**Section IV.D**)

| Model (Akida SNN)       | Top-1 Accuracy (%) | Macro F1 Score (%) |
|-------------------------|--------------------|---------------------|
| ResNet-50               | 85.7               | 76.4                |
| DenseNet-121            | 86.5               | 77.2                |
| EfficientNet-B4         | 87.3               | 78.1                |
| CNN Ensemble (Top-3)    | 88.1               | 78.9                |
| **Ours**                | **91.6**           | **82.4**            |

> **Explanation:** Compared to other state-of-the-art CNNs converted to SNNs, our model achieves the highest accuracy and F1 under the same hardware and quantization constraints.

---

### Latency and Energy Efficiency  
(**Section IV.E**)

| Model              | Latency (ms) | Energy (mJ) | â†“ vs GPU (%) |
|-------------------|--------------|-------------|---------------|
| ResNet-50         | 2.8          | 3.3         | 76.9 / 98.1    |
| MobileNet-v2      | 2.2          | 2.6         | 68.1 / 97.3    |
| CNN Ensemble      | 7.5          | 8.6         | 79.2 / 98.1    |
| **Ours**          | **1.5**      | **1.7**     | **94.6 / 99.0** |

> **Explanation:** Our Akida-deployed model achieves the fastest inference and lowest power consumption across all benchmarks, enabling real-time, battery-powered diagnostic systems.

---

### ðŸ§ª Ablation Study  
(**Section IV.F**)

| Ghost | ECA | SE | Quant Head | SMOTE | Inc Learn | Accuracy | F1    |
|-------|-----|----|-------------|-------|------------|----------|-------|
| âœ—     | âœ—   | âœ—  | âœ—           | âœ—     | âœ—          | 84.1     | 81.6  |
| âœ“     | âœ—   | âœ—  | âœ—           | âœ—     | âœ—          | 86.3     | 83.6  |
| âœ“     | âœ“   | âœ“  | âœ“           | âœ“     | âœ“          | **91.6** | **90.9** |

> **Explanation:** Each architectural component incrementally improves performance. The full model achieves maximum accuracy, proving the effectiveness of Ghost, ECA, SE, quantization, and incremental learning.

---

### ðŸ¥ Generalization on Clinical Dataset  
(**Section IV.G**)

| Model (SNN on Akida)      | Top-1 Accuracy (%) | Macro F1 Score (%) |
|---------------------------|--------------------|---------------------|
| DenseNet-121              | 85.7               | 76.2                |
| CNN Ensemble              | 87.6               | 78.1                |
| **Ours**                  | **90.8**           | **81.7**            |

> **Explanation:** On real-world hospital data from Nanjing Drum Tower Hospital, our model outperforms other methods, confirming generalization to clinical cases beyond benchmarks.

---

