{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GENG5551 Prototype Model Training \n",
        "\n",
        "Run code below if using google collab for training. If not skip to next section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAJmzS0hM7Rv"
      },
      "source": [
        "run container with:\n",
        "sudo docker run --gpus all -it --rm -v $(pwd):/tf/notebooks -p 8888:8888 tensorflow/tensorflow:2.12.0-gpu-jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "startup = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZATueY_Yc9vt",
        "outputId": "93ddd5f3-f3ec-4b90-f677-ceae6228a022"
      },
      "outputs": [],
      "source": [
        "# GB: Useless\n",
        "\n",
        "# !pip install pandas\n",
        "# !pip install scikit-learn\n",
        "# !pip install seaborn\n",
        "# !pip install akida==2.7.2\n",
        "# !pip install cnn2snn==2.7.2\n",
        "# %pip install akida-models==1.5.0\n",
        "# !pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GB: Same here\n",
        "# !unzip notebooks/archive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Preprocessing\n",
        "\n",
        "Start here if running on anaconda virtual environment\n",
        "\n",
        "- This section involves examining and pre-processing the data to make it suitable for use with the Akida models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSYTr1lRcyvc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, shutil, random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import cnn2snn\n",
        "import akida as ak\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy, BinaryCrossentropy, CategoricalCrossentropy \n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from akida_models import fetch_file, akidanet_imagenet, mobilenet_imagenet\n",
        "from keras import Model\n",
        "from keras.layers import Activation, Dropout, Reshape\n",
        "from akida_models.layer_blocks import dense_block, conv_block\n",
        "import re\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "os.chdir('notebooks/Documents/GitHub/GENG5551-Akida-Chip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.getcwd()\n",
        "# Change Akida version\n",
        "os.environ[\"CNN2SNN_TARGET_AKIDA_VERSION\"] = \"v1\"\n",
        "# Double-check Avida version\n",
        "print(' Akida version: ', cnn2snn.get_akida_version())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xI85A6Qcyvd"
      },
      "outputs": [],
      "source": [
        "# Load the metadata\n",
        "metadata = pd.read_csv('archive/HAM10000_metadata.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define paths for train and test datasets\n",
        "train_dir = 'archive/data/train'\n",
        "test_dir = 'archive/data/test'\n",
        "\n",
        "# Define the target directories for cancerous and benign images\n",
        "train_cancerous_dir = 'archive/data/train/Cancerous'\n",
        "train_benign_dir = 'archive/data/train/Benign'\n",
        "test_cancerous_dir = 'archive/data/test/Cancerous'\n",
        "test_benign_dir = 'archive/data/test/Benign'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    channel_shift_range=50.0\n",
        ")\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=100,\n",
        "    class_mode='binary',\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator()\n",
        "test_gen = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=100,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "IMG_SIZE = 224\n",
        "CLASSES = 2\n",
        "\n",
        "\n",
        "# Create a base model without top layers\n",
        "base_model = akidanet_imagenet(input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "                            classes=CLASSES,\n",
        "                            alpha=0.5,\n",
        "                            include_top=False,\n",
        "                            pooling='None')\n",
        "\n",
        "base_model.load_weights(f'pretrained_weights/akidanet_imagenet_224_alpha_50.h5', by_name=True)\n",
        "\n",
        "x = base_model.output\n",
        "x = conv_block(x,\n",
        "               filters=64,\n",
        "               kernel_size=(3,3),\n",
        "               add_batchnorm=True,\n",
        "               relu_activation='ReLU6',\n",
        "               name='extra_conv')\n",
        "\n",
        "# Now apply global average pooling\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = dense_block(x,\n",
        "                units=512,\n",
        "                name='fc1',\n",
        "                add_batchnorm=True,\n",
        "                relu_activation='ReLU6')\n",
        "x = Dropout(0.5, name='dropout_1')(x)\n",
        "x = dense_block(x,\n",
        "                units=CLASSES,\n",
        "                name='predictions',\n",
        "                add_batchnorm=False,\n",
        "                relu_activation=False)\n",
        "\n",
        "x = Reshape((CLASSES,), name='reshape1')(x)\n",
        "\n",
        "# Build the model\n",
        "model_keras = Model(base_model.input, x, name='akidanet_derma')\n",
        "\n",
        "initial_learning_rate = 1e-3\n",
        "final_learning_rate = 1e-5\n",
        "decay_steps = 10\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps,\n",
        "    decay_rate=(final_learning_rate / initial_learning_rate) ** (1 / decay_steps),\n",
        "    staircase=True)\n",
        "\n",
        "\n",
        "loss = BinaryCrossentropy()\n",
        "\n",
        "\n",
        "optimizer = RMSprop(\n",
        "    learning_rate=1e-3,\n",
        "    rho=0.9,\n",
        "    momentum=0.0,\n",
        "    epsilon=1e-7\n",
        ")\n",
        "\n",
        "# Compiling the model\n",
        "model_keras.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss,\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Setting up callbacks for saving the model and early stopping\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    'akidanet_derma_best.h5', save_best_only=True)\n",
        "early_stopping_cb = EarlyStopping(\n",
        "    patience=10, restore_best_weights=True)\n",
        "\n",
        "# GB: To change nb of epochs \n",
        "# (on CPU, 1 epoch lasts 22 min, so 10 is 4 hours long)\n",
        "EPOCHS = 15 # Initial value: 10\n",
        "\n",
        "# Training the model\n",
        "history = model_keras.fit(\n",
        "    train_gen,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=test_gen,\n",
        "    callbacks=[checkpoint_cb, early_stopping_cb])\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_fine_tune.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history_fine_tune.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_fine_tune.history['loss'], label='Training Loss')\n",
        "plt.plot(history_fine_tune.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "mod1_fname = f\"new_model.h5\"\n",
        "model_keras.save(mod1_fname)\n",
        "\n",
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Obtain predictions for the training and validation datasets\n",
        "train_predictions = np.argmax(model_keras.predict(train_gen), axis=-1)\n",
        "val_predictions = np.argmax(model_keras.predict(test_gen), axis=-1)\n",
        "\n",
        "# Get true labels from the generators\n",
        "train_labels = train_gen.classes\n",
        "val_labels = test_gen.classes\n",
        "\n",
        "# Compute confusion matrices\n",
        "train_cm = confusion_matrix(train_labels, train_predictions)\n",
        "val_cm = confusion_matrix(val_labels, val_predictions)\n",
        "\n",
        "# Plot confusion matrix for training data\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "ConfusionMatrixDisplay(confusion_matrix=train_cm).plot(cmap='Blues', ax=plt.gca())\n",
        "plt.title('Confusion Matrix for Training Data')\n",
        "\n",
        "# Plot confusion matrix for validation data\n",
        "plt.subplot(1, 2, 2)\n",
        "ConfusionMatrixDisplay(confusion_matrix=val_cm).plot(cmap='Blues', ax=plt.gca())\n",
        "plt.title('Confusion Matrix for Validation Data')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_sizes = [32, 64, 100]\n",
        "class_modes = ['binary', 'categorical', 'sparse']\n",
        "base_model_origin = os.listdir('pretrained_weights')\n",
        "optimizers = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "radam_optimizer = tfa.optimizers.RectifiedAdam(\n",
        "    learning_rate=1e-3,  # Start with your current learning rate\n",
        "    total_steps=10000,  # Total number of training steps\n",
        "    warmup_proportion=0.1,  # 10% of the steps are used for learning rate warmup\n",
        "    min_lr=1e-5  # The minimum learning rate after decay\n",
        ")\n",
        "\n",
        "optimizer = RMSprop(\n",
        "    learning_rate=1e-3,\n",
        "    rho=0.9,\n",
        "    momentum=0.0,\n",
        "    epsilon=1e-7\n",
        ")\n",
        "\n",
        "optimizers.append(radam_optimizer)\n",
        "optimizers.append(optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 38704 images belonging to 2 classes.\n",
            "Found 1002 images belonging to 2 classes.\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Shape mismatch in layer #2 (named conv_0) for weight conv_0/kernel:0. Weight expects shape (3, 3, 3, 32). Received saved weight with shape (16, 3, 3, 3)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[32], line 43\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Create a base model without top layers\u001b[39;00m\n\u001b[1;32m     37\u001b[0m base_model \u001b[38;5;241m=\u001b[39m akidanet_imagenet(input_shape\u001b[38;5;241m=\u001b[39m(IMG_SIZE, IMG_SIZE, \u001b[38;5;241m3\u001b[39m),\n\u001b[1;32m     38\u001b[0m                             classes\u001b[38;5;241m=\u001b[39mCLASSES,\n\u001b[1;32m     39\u001b[0m                             alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[1;32m     40\u001b[0m                             include_top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     41\u001b[0m                             pooling\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m \u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpretrained_weights/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbase_model_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# layer freezing\u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/legacy/hdf5_format.py:935\u001b[0m, in \u001b[0;36mload_weights_from_hdf5_group_by_name\u001b[0;34m(f, model, skip_mismatch)\u001b[0m\n\u001b[1;32m    926\u001b[0m         logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    927\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping loading weights for layer #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (named \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    928\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) due to mismatch in shape for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreceived_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    933\u001b[0m         )\n\u001b[1;32m    934\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape mismatch in layer #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor weight \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbolic_weights[i]\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeight expects shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived saved weight \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    940\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreceived_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    941\u001b[0m     )\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    943\u001b[0m     weight_value_tuples\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    944\u001b[0m         (symbolic_weights[i], weight_values[i])\n\u001b[1;32m    945\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: Shape mismatch in layer #2 (named conv_0) for weight conv_0/kernel:0. Weight expects shape (3, 3, 3, 32). Received saved weight with shape (16, 3, 3, 3)"
          ]
        }
      ],
      "source": [
        "for batch_size in batch_sizes:\n",
        "    for class_mode in class_modes:\n",
        "        for base_model_path in base_model_origin:\n",
        "            for optimizer in optimizers:\n",
        "                # Construct train datagen\n",
        "                train_datagen = ImageDataGenerator(\n",
        "                    rotation_range=20,\n",
        "                    width_shift_range=0.2,\n",
        "                    height_shift_range=0.2,\n",
        "                    shear_range=0.2,\n",
        "                    zoom_range=0.2,\n",
        "                    horizontal_flip=True,\n",
        "                    brightness_range=[0.8, 1.2],\n",
        "                    channel_shift_range=50.0\n",
        "                )\n",
        "\n",
        "                train_gen = train_datagen.flow_from_directory(\n",
        "                    train_dir,\n",
        "                    target_size=(224, 224),\n",
        "                    batch_size=batch_size,\n",
        "                    class_mode=class_mode,\n",
        "                )\n",
        "\n",
        "                test_datagen = ImageDataGenerator()\n",
        "                test_gen = test_datagen.flow_from_directory(\n",
        "                    test_dir,\n",
        "                    target_size=(224, 224),\n",
        "                    batch_size=100,\n",
        "                    class_mode=class_mode\n",
        "                )\n",
        "\n",
        "                IMG_SIZE = 224\n",
        "                CLASSES = 2\n",
        "\n",
        "\n",
        "                # Create a base model without top layers\n",
        "                base_model = akidanet_imagenet(input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "                                            classes=CLASSES,\n",
        "                                            alpha=1.0,\n",
        "                                            include_top=False,\n",
        "                                            pooling='avg')\n",
        "\n",
        "                base_model.load_weights(f'pretrained_weights/{base_model_path}', by_name=True)\n",
        "                print(\"Hello\")\n",
        "                # layer freezing\n",
        "                for layer in base_model.layers:\n",
        "                    layer.trainable = False\n",
        "\n",
        "                x = base_model.output\n",
        "                x = dense_block(x,\n",
        "                                units=512,\n",
        "                                name='fc1',\n",
        "                                add_batchnorm=True,\n",
        "                                relu_activation='ReLU6')\n",
        "                x = Dropout(0.5, name='dropout_1')(x)\n",
        "                x = dense_block(x,\n",
        "                                units=CLASSES,\n",
        "                                name='predictions',\n",
        "                                add_batchnorm=False,\n",
        "                                relu_activation=False)\n",
        "\n",
        "                x = Reshape((CLASSES,), name='reshape1')(x)\n",
        "\n",
        "                # Build the model\n",
        "                model_keras = Model(base_model.input, x, name='akidanet_derma')\n",
        "\n",
        "                initial_learning_rate = 1e-3\n",
        "                final_learning_rate = 1e-5\n",
        "                decay_steps = 10\n",
        "                lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "                    initial_learning_rate,\n",
        "                    decay_steps,\n",
        "                    decay_rate=(final_learning_rate / initial_learning_rate) ** (1 / decay_steps),\n",
        "                    staircase=True)\n",
        "                \n",
        "\n",
        "                if class_mode == 'binary':\n",
        "                    loss = BinaryCrossentropy()\n",
        "                elif class_mode == 'categorical':\n",
        "                    loss = CategoricalCrossentropy()\n",
        "                elif class_mode == 'sparse':\n",
        "                    loss = SparseCategoricalCrossentropy()\n",
        "\n",
        "                # Compiling the model\n",
        "                model_keras.compile(\n",
        "                    optimizer=optimizer,\n",
        "                    loss=loss,\n",
        "                    metrics=['accuracy'])\n",
        "                \n",
        "\n",
        "                # Setting up callbacks for saving the model and early stopping\n",
        "                checkpoint_cb = ModelCheckpoint(\n",
        "                    'akidanet_derma_best.h5', save_best_only=True)\n",
        "                early_stopping_cb = EarlyStopping(\n",
        "                    patience=10, restore_best_weights=True)\n",
        "\n",
        "                # GB: To change nb of epochs \n",
        "                # (on CPU, 1 epoch lasts 22 min, so 10 is 4 hours long)\n",
        "                EPOCHS = 15 # Initial value: 10\n",
        "\n",
        "                # Training the model\n",
        "                history = model_keras.fit(\n",
        "                    train_gen,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=test_gen,\n",
        "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
        "                \n",
        "                number = re.search(r'(\\d+)(?=\\.h5)', base_model_path).group()\n",
        "                \n",
        "                if isinstance(optimizer, tfa.optimizers.RectifiedAdam):\n",
        "                    op = \"Radam\"\n",
        "                elif isinstance(optimizer, RMSprop):\n",
        "                    op = \"RMSprop\"\n",
        "\n",
        "\n",
        "                mod1_fname = f\"freeze_{batch_size}_{class_mode}_{number}_{op}.h5\"\n",
        "                model_keras.save(mod1_fname)\n",
        "\n",
        "                # Fine-tuning frozen layers\n",
        "                for layer in base_model.layers[-5:]:\n",
        "                    layer.trainable = True\n",
        "\n",
        "                fine_tuning_lr = 1e-4\n",
        "                model_keras.compile(\n",
        "                    optimizer=optimizer,\n",
        "                    loss=loss,\n",
        "                    metrics=['accuracy']\n",
        "                )\n",
        "\n",
        "                EPOCHS_FINE_TUNE = 10\n",
        "\n",
        "                history_fine_tune = model_keras.fit(\n",
        "                    train_gen,\n",
        "                    epochs=EPOCHS_FINE_TUNE,\n",
        "                    validation_data=test_gen,\n",
        "                    callbacks=[checkpoint_cb, early_stopping_cb]\n",
        "                )\n",
        "\n",
        "                mod2_fname = f\"unfreeze_{batch_size}_{class_mode}_{number}_{op}.h5\"\n",
        "                model_keras.save(mod2_fname)\n",
        "\n",
        "                tf.keras.backend.clear_session()\n",
        "\n",
        "\n",
        "                \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
